# Instrument Recognition in Musical Audio Signals 
The goal of this project is to classify instruments in music audio signals. To do so, we have implemented a VGG-like model that is trained with the Mel Log Spectrograms extracted from the data in the IRMAS dataset.

### Getting started
Download a copy of this repository. Extract the zip file and upload it to your drive. The path to the repository folder should be */content/drive/My Drive/DeepLearning_2020/*

Also, download the files in  https://drive.google.com/drive/folders/1PCZbU3EFrr0Ek2II3MtZ8QsX-o3S0cMA?usp=sharing and store them in */content/drive/My Drive/DeepLearning_2020/Data/*

### Prerequisites
Google Colab

### Deployment
Run the whole notebook. Mount drive when prompted.

### Built With
* [PyTorch](https://pytorch.org) - An open source machine learning framework
* [Essentia](https://essentia.upf.edu) - Open-source library and tools for audio and music analysis, description and synthesis

### Authors
* [Claudia Herron Mulet](https://www.linkedin.com/in/claudiaherronmulet/)
* Júlia Riera Perramón
* [Sara Estévez Manteiga](www.linkedin.com/in/saraestevezmanteiga/)


### Acknowledgments
Xavier Favory, researcher at the Audio Signal Processing Lab at UPF, for the code provided to start this project.

Bosch, J. J., Janer, J., Fuhrmann, F., & Herrera, P. “A Comparison of Sound Segregation Techniques for Predominant Instrument Recognition in Musical Audio Signals”, in Proc. ISMIR (pp. 559-564), 2012

